{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정재환\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from matplotlib import font_manager, rc\n",
    "import numpy as np\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트 적용 - 한글깨짐 방지\n",
    "font_name = font_manager.FontProperties(fname='c:/Windows/Fonts/malgun.ttf').get_name()\n",
    "rc('font', family=font_name)\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>번호</th>\n",
       "      <th>성별</th>\n",
       "      <th>연령</th>\n",
       "      <th>신장</th>\n",
       "      <th>체중</th>\n",
       "      <th>허리둘레</th>\n",
       "      <th>수축기혈압</th>\n",
       "      <th>이완기혈압</th>\n",
       "      <th>식전혈당</th>\n",
       "      <th>총콜레스테롤</th>\n",
       "      <th>흡연상태</th>\n",
       "      <th>음주여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>90.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>165</td>\n",
       "      <td>75</td>\n",
       "      <td>91.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>91.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199772</th>\n",
       "      <td>199772</td>\n",
       "      <td>199996</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "      <td>107.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199773</th>\n",
       "      <td>199773</td>\n",
       "      <td>199997</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>155</td>\n",
       "      <td>45</td>\n",
       "      <td>63.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199774</th>\n",
       "      <td>199774</td>\n",
       "      <td>199998</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199775</th>\n",
       "      <td>199775</td>\n",
       "      <td>199999</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>88.2</td>\n",
       "      <td>147.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199776</th>\n",
       "      <td>199776</td>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>83.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199777 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      번호  성별  연령   신장   체중   허리둘레  수축기혈압  이완기혈압   식전혈당  \\\n",
       "0                0       1   1  40  170   75   90.0  120.0   80.0   99.0   \n",
       "1                1       2   1  35  180   80   89.0  130.0   82.0  106.0   \n",
       "2                2       3   1  45  165   75   91.0  120.0   70.0   98.0   \n",
       "3                3       4   1  55  175   80   91.0  145.0   87.0   95.0   \n",
       "4                4       5   1  55  165   60   80.0  138.0   82.0  101.0   \n",
       "...            ...     ...  ..  ..  ...  ...    ...    ...    ...    ...   \n",
       "199772      199772  199996   1  45  170  100  107.0  135.0   88.0  112.0   \n",
       "199773      199773  199997   2  30  155   45   63.0  107.0   61.0   83.0   \n",
       "199774      199774  199998   1  55  160   70   91.0  100.0   76.0  100.0   \n",
       "199775      199775  199999   1  40  170   75   88.2  147.0   89.0   81.0   \n",
       "199776      199776  200000   1  60  165   60   83.0  112.0   66.0  104.0   \n",
       "\n",
       "        총콜레스테롤  흡연상태  음주여부  \n",
       "0        193.0   1.0   1.0  \n",
       "1        228.0   3.0   0.0  \n",
       "2        136.0   1.0   0.0  \n",
       "3        201.0   1.0   0.0  \n",
       "4        199.0   1.0   0.0  \n",
       "...        ...   ...   ...  \n",
       "199772   247.0   3.0   1.0  \n",
       "199773   151.0   1.0   1.0  \n",
       "199774   222.0   1.0   0.0  \n",
       "199775   125.0   3.0   1.0  \n",
       "199776   212.0   3.0   0.0  \n",
       "\n",
       "[199777 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv 파일 읽어와서 데이터프레임에 저장\n",
    "df_source = pd.read_csv('NHIS_OPEN_GJ_2017_3.csv', encoding='cp949')\n",
    "df_source = df_source.drop_duplicates() # 중복값 제거\n",
    "df_source = df_source.dropna() # 결측값 제거\n",
    "df_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_source.drop(['성별', '번호', 'Unnamed: 0'], axis=1) # 성별특성을 제외한 모든 특성의 데이터\n",
    "y = df_source['성별']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 셋 정확도: 0.9222\n",
      "훈련 셋 정확도: 0.9217\n"
     ]
    }
   ],
   "source": [
    "# 훈련, 테스트 셋 분리\n",
    "# test_size=0.3으로 설정하여 훈련:테스트 비율을 7:3으로\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 표준화 전처리 적용\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaler = scaler.transform(x_train)\n",
    "x_train_scaler = pd.DataFrame(x_train_scaler, columns = x_train.columns) # 표준화를 적용한 이후 다시 컬럼명을 지정해야 한다 \n",
    "del scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test)\n",
    "x_test_scaler = scaler.transform(x_test)\n",
    "x_test_scaler = pd.DataFrame(x_test_scaler, columns = x_test.columns)\n",
    "\n",
    "# solver 속성은 경사하강법 알고리즘 종류를 설정한다. sgd를 적용하여 확률적 경사하강법으로 설정한다\n",
    "# alpha 속성을 사용해 L2규제를 적용할 수 있다\n",
    "# batch_size 속성으로 전체 데이터의 크기를 조정한다\n",
    "# learning_rate_init속성에 0.1을 설정하여 가중치 값을 10% 만큼 반영한다\n",
    "# max_iter 를 사용해 최대 반복횟수를 지정한다\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='sgd', alpha=0.01, batch_size=10,\n",
    "                   learning_rate_init=0.1, max_iter=500) # 딥러닝 객체 생성\n",
    "mlp.fit(x_train_scaler, y_train)\n",
    "\n",
    "# 테스트 셋 정확도 \n",
    "accuracy = float(mlp.score(x_test_scaler, y_test))\n",
    "print('테스트 셋 정확도: %.4f' %accuracy)\n",
    "\n",
    "# 훈련 셋 정확도 \n",
    "accuracy = float(mlp.score(x_train_scaler, y_train))\n",
    "print('훈련 셋 정확도: %.4f' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 셋 에서는 92%, 훈련 셋 에서는 92%의 정확도가 나타난다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mlp, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에는 alpha를 0.1로 설정하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 셋 정확도: 0.9098\n",
      "훈련 셋 정확도: 0.9076\n"
     ]
    }
   ],
   "source": [
    "# 훈련, 테스트 셋 분리\n",
    "# test_size=0.3으로 설정하여 훈련:테스트 비율을 7:3으로\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 표준화 전처리 적용\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaler = scaler.transform(x_train)\n",
    "x_train_scaler = pd.DataFrame(x_train_scaler, columns = x_train.columns) # 표준화를 적용한 이후 다시 컬럼명을 지정해야 한다 \n",
    "del scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test)\n",
    "x_test_scaler = scaler.transform(x_test)\n",
    "x_test_scaler = pd.DataFrame(x_test_scaler, columns = x_test.columns)\n",
    "\n",
    "# solver 속성은 경사하강법 알고리즘 종류를 설정한다. sgd를 적용하여 확률적 경사하강법으로 설정한다\n",
    "# alpha 속성을 사용해 L2규제를 적용할 수 있다\n",
    "# batch_size 속성으로 전체 데이터의 크기를 조정한다\n",
    "# learning_rate_init속성에 0.1을 설정하여 가중치 값을 10% 만큼 반영한다\n",
    "# max_iter 를 사용해 최대 반복횟수를 지정한다\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='sgd', alpha=0.1, batch_size=10,\n",
    "                   learning_rate_init=0.1, max_iter=500) # 딥러닝 객체 생성\n",
    "mlp.fit(x_train_scaler, y_train)\n",
    "\n",
    "# 테스트 셋 정확도 \n",
    "accuracy = float(mlp.score(x_test_scaler, y_test))\n",
    "print('테스트 셋 정확도: %.4f' %accuracy)\n",
    "\n",
    "# 훈련 셋 정확도 \n",
    "accuracy = float(mlp.score(x_train_scaler, y_train))\n",
    "print('훈련 셋 정확도: %.4f' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전과 비교하여 정확도가 2% 정도 감소하였다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mlp, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에는 은닉층(hidden_layer_sizes)을 3개만 설정하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 셋 정확도: 0.9189\n",
      "훈련 셋 정확도: 0.9185\n"
     ]
    }
   ],
   "source": [
    "# 훈련, 테스트 셋 분리\n",
    "# test_size=0.3으로 설정하여 훈련:테스트 비율을 7:3으로\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 표준화 전처리 적용\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaler = scaler.transform(x_train)\n",
    "x_train_scaler = pd.DataFrame(x_train_scaler, columns = x_train.columns) # 표준화를 적용한 이후 다시 컬럼명을 지정해야 한다 \n",
    "del scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test)\n",
    "x_test_scaler = scaler.transform(x_test)\n",
    "x_test_scaler = pd.DataFrame(x_test_scaler, columns = x_test.columns)\n",
    "\n",
    "# solver 속성은 경사하강법 알고리즘 종류를 설정한다. sgd를 적용하여 확률적 경사하강법으로 설정한다\n",
    "# alpha 속성을 사용해 L2규제를 적용할 수 있다\n",
    "# batch_size 속성으로 전체 데이터의 크기를 조정한다\n",
    "# learning_rate_init속성에 0.1을 설정하여 가중치 값을 10% 만큼 반영한다\n",
    "# max_iter 를 사용해 최대 반복횟수를 지정한다\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(3,), activation='logistic', solver='sgd', alpha=0.01, batch_size=10,\n",
    "                   learning_rate_init=0.1, max_iter=500) # 딥러닝 객체 생성\n",
    "mlp.fit(x_train_scaler, y_train)\n",
    "\n",
    "# 테스트 셋 정확도 \n",
    "accuracy = float(mlp.score(x_test_scaler, y_test))\n",
    "print('테스트 셋 정확도: %.4f' %accuracy)\n",
    "\n",
    "# 훈련 셋 정확도 \n",
    "accuracy = float(mlp.score(x_train_scaler, y_train))\n",
    "print('훈련 셋 정확도: %.4f' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층 수를 감소시켰을 때 예측 정확도는 이전과 큰 차이가 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mlp, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에는 최대반복횟수를(max_iter)를 100번으로 설정하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 셋 정확도: 0.9208\n",
      "훈련 셋 정확도: 0.9206\n"
     ]
    }
   ],
   "source": [
    "# 훈련, 테스트 셋 분리\n",
    "# test_size=0.3으로 설정하여 훈련:테스트 비율을 7:3으로\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 표준화 전처리 적용\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaler = scaler.transform(x_train)\n",
    "x_train_scaler = pd.DataFrame(x_train_scaler, columns = x_train.columns) # 표준화를 적용한 이후 다시 컬럼명을 지정해야 한다 \n",
    "del scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test)\n",
    "x_test_scaler = scaler.transform(x_test)\n",
    "x_test_scaler = pd.DataFrame(x_test_scaler, columns = x_test.columns)\n",
    "\n",
    "# solver 속성은 경사하강법 알고리즘 종류를 설정한다. sgd를 적용하여 확률적 경사하강법으로 설정한다\n",
    "# alpha 속성을 사용해 L2규제를 적용할 수 있다\n",
    "# batch_size 속성으로 전체 데이터의 크기를 조정한다\n",
    "# learning_rate_init속성에 0.1을 설정하여 가중치 값을 10% 만큼 반영한다\n",
    "# max_iter 를 사용해 최대 반복횟수를 지정한다\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='sgd', alpha=0.01, batch_size=10,\n",
    "                   learning_rate_init=0.1, max_iter=100) # 딥러닝 객체 생성\n",
    "mlp.fit(x_train_scaler, y_train)\n",
    "\n",
    "# 테스트 셋 정확도 \n",
    "accuracy = float(mlp.score(x_test_scaler, y_test))\n",
    "print('테스트 셋 정확도: %.4f' %accuracy)\n",
    "\n",
    "# 훈련 셋 정확도 \n",
    "accuracy = float(mlp.score(x_train_scaler, y_train))\n",
    "print('훈련 셋 정확도: %.4f' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전과 비교하여 정확도가 거의 비슷하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mlp, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에는 전체데이터 크기(batch_size)를 2로 감소하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 셋 정확도: 0.8901\n",
      "훈련 셋 정확도: 0.8884\n"
     ]
    }
   ],
   "source": [
    "# 훈련, 테스트 셋 분리\n",
    "# test_size=0.3으로 설정하여 훈련:테스트 비율을 7:3으로\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 표준화 전처리 적용\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaler = scaler.transform(x_train)\n",
    "x_train_scaler = pd.DataFrame(x_train_scaler, columns = x_train.columns) # 표준화를 적용한 이후 다시 컬럼명을 지정해야 한다 \n",
    "del scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test)\n",
    "x_test_scaler = scaler.transform(x_test)\n",
    "x_test_scaler = pd.DataFrame(x_test_scaler, columns = x_test.columns)\n",
    "\n",
    "# solver 속성은 경사하강법 알고리즘 종류를 설정한다. sgd를 적용하여 확률적 경사하강법으로 설정한다\n",
    "# alpha 속성을 사용해 L2규제를 적용할 수 있다\n",
    "# batch_size 속성으로 전체 데이터의 크기를 조정한다\n",
    "# learning_rate_init속성에 0.1을 설정하여 가중치 값을 10% 만큼 반영한다\n",
    "# max_iter 를 사용해 최대 반복횟수를 지정한다\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='sgd', alpha=0.01, batch_size=2,\n",
    "                   learning_rate_init=0.1, max_iter=300) # 딥러닝 객체 생성\n",
    "mlp.fit(x_train_scaler, y_train)\n",
    "\n",
    "# 테스트 셋 정확도 \n",
    "accuracy = float(mlp.score(x_test_scaler, y_test))\n",
    "print('테스트 셋 정확도: %.4f' %accuracy)\n",
    "\n",
    "# 훈련 셋 정확도 \n",
    "accuracy = float(mlp.score(x_train_scaler, y_train))\n",
    "print('훈련 셋 정확도: %.4f' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체데이터 크기(batch_size)를 감소시킨 결과 정확도가 3~4% 정도 감소하였다, 실행시간이 오래걸렸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mlp, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에는 전체데이터 크기(batch_size)를 100으로 증가하여 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 셋 정확도: 0.9291\n",
      "훈련 셋 정확도: 0.9294\n"
     ]
    }
   ],
   "source": [
    "# 훈련, 테스트 셋 분리\n",
    "# test_size=0.3으로 설정하여 훈련:테스트 비율을 7:3으로\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 표준화 전처리 적용\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaler = scaler.transform(x_train)\n",
    "x_train_scaler = pd.DataFrame(x_train_scaler, columns = x_train.columns) # 표준화를 적용한 이후 다시 컬럼명을 지정해야 한다 \n",
    "del scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test)\n",
    "x_test_scaler = scaler.transform(x_test)\n",
    "x_test_scaler = pd.DataFrame(x_test_scaler, columns = x_test.columns)\n",
    "\n",
    "# solver 속성은 경사하강법 알고리즘 종류를 설정한다. sgd를 적용하여 확률적 경사하강법으로 설정한다\n",
    "# alpha 속성을 사용해 L2규제를 적용할 수 있다\n",
    "# batch_size 속성으로 전체 데이터의 크기를 조정한다\n",
    "# learning_rate_init속성에 0.1을 설정하여 가중치 값을 10% 만큼 반영한다\n",
    "# max_iter 를 사용해 최대 반복횟수를 지정한다\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(8,), activation='logistic', solver='sgd', alpha=0.01, batch_size=100,\n",
    "                   learning_rate_init=0.1, max_iter=300) # 딥러닝 객체 생성\n",
    "mlp.fit(x_train_scaler, y_train)\n",
    "\n",
    "# 테스트 셋 정확도 \n",
    "accuracy = float(mlp.score(x_test_scaler, y_test))\n",
    "print('테스트 셋 정확도: %.4f' %accuracy)\n",
    "\n",
    "# 훈련 셋 정확도 \n",
    "accuracy = float(mlp.score(x_train_scaler, y_train))\n",
    "print('훈련 셋 정확도: %.4f' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체데이터크기(batch_size)를 100으로 증가시킨 결과 정확도가 이전보다 약 1% 정도 증가하였고 실행시간도 짧아졌다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mlp, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
